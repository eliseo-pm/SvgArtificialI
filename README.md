# SVG AI Generator

Este proyecto entrena un modelo de lenguaje basado en Transformers (como GPT-2) para generar contenido SVG (Ã­conos, logos, dibujos) a partir de un dataset personalizado. Utiliza Hugging Face Transformers y PyTorch.

---

## ğŸ§  Requisitos

- Python 3.10 o 3.11
- Linux o WSL (ideal)
- Entorno virtual (`venv`)
- Dataset en formato `.jsonl` (ej. `training_data.jsonl`)
- Internet (para descargar modelos preentrenados)

---

## ğŸ“¦ InstalaciÃ³n

1. Clona este repositorio:

bash
git clone https://github.com/tuusuario/svgai.git
cd svgai
Crea y activa un entorno virtual:

bash
python3 -m venv venv
source venv/bin/activate
Instala dependencias:

bash
pip install -r requirements.txt
O si no tienes requirements.txt:

bash
pip install torch transformers datasets accelerate
âš ï¸ Para soporte de GPU con CUDA (opcional):

bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
ğŸ“ Estructura esperada
bash
svgai/
â”œâ”€â”€ train_svg_model.py
â”œâ”€â”€ training_data.jsonl
â”œâ”€â”€ logs/              # Se crea automÃ¡ticamente durante entrenamiento
â”œâ”€â”€ svg-model/         # Se crea automÃ¡ticamente durante entrenamiento
â””â”€â”€ venv/              # Entorno virtual, lo creas tÃº
â„¹ï¸ Los directorios venv/, logs/ y svg-model/ han sido eliminados del repositorio para ahorrar espacio. Se generarÃ¡n automÃ¡ticamente al correr el proyecto localmente.

ğŸ‹ï¸ Entrenamiento
Ejecuta el script principal:

bash
python train_svg_model.py
Este iniciarÃ¡ el fine-tuning del modelo en tu dataset personalizado.

Argumentos usados en el Trainer:
output_dir="./svg-model"

overwrite_output_dir=True

num_train_epochs=50

per_device_train_batch_size=2

save_steps=500

save_total_limit=2

logging_steps=100

logging_dir="./logs"

fp16=True

report_to="none"

ğŸ”„ Reanudar desde Checkpoint
Si pausas el entrenamiento (ej. con Ctrl+C), puedes reanudarlo:

Edita el script:

python
trainer.train(resume_from_checkpoint=True)
Y vuelve a correr:

bash
python train_svg_model.py
ğŸ“¤ Exportar el modelo entrenado
DespuÃ©s del entrenamiento, el modelo se guarda en ./svg-model. Puedes usarlo asÃ­:

python
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("./svg-model")
model = AutoModelForCausalLM.from_pretrained("./svg-model")
ğŸ›  Dataset esperado
Archivo .jsonl con lÃ­neas como:

json
{"prompt": "<svg ...>...</svg>"}
Cada lÃ­nea representa un SVG vÃ¡lido como texto.

âœ… Recomendaciones
Usa batch size pequeÃ±o si no tienes GPU potente.

Usa fp16=True solo si tu GPU lo soporta.

Haz pruebas con 1â€“2 epochs antes de un entrenamiento largo.

ğŸ§‘â€ğŸ’» Autor
Desarrollado por [Tu Nombre o Alias]

ğŸ“„ Licencia
MIT
